{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjtuiiot/.pyenv/versions/anaconda3-4.4.0/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_slice(data, time_steps):\n",
    "    data = np.transpose(data, (1, 0, 2)).reshape(-1, 310)\n",
    "    xs = []\n",
    "    for i in range(data.shape[0] - time_steps + 1):\n",
    "        xs.append(data[i: i + time_steps])\n",
    "    xs = np.concatenate(xs).reshape((len(xs), -1, 310))\n",
    "    return xs\n",
    "\n",
    "    \n",
    "def load_data(data_file, label_file, time_steps):\n",
    "    datas = np.load(data_file)\n",
    "    labels = np.load(label_file)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for data, label in zip([datas[k] for k in datas.keys()[:9]], list(labels[:9])):\n",
    "        X_train.append(window_slice(data, time_steps))\n",
    "        y_train.extend([label] * len(X_train[-1]))\n",
    "    for data, label in zip([datas[k] for k in datas.keys()[9:]], list(labels[9:])):\n",
    "        X_test.append(window_slice(data, time_steps))\n",
    "        y_test.extend([label] * len(X_test[-1]))\n",
    "    return np.concatenate(X_train), np.concatenate(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unrolled through 28 time steps\n",
    "time_steps=50\n",
    "#hidden LSTM units\n",
    "num_units=128\n",
    "#rows of 28 pixels\n",
    "features=310\n",
    "#learning rate for adam\n",
    "learning_rate=0.001\n",
    "#mnist is meant to be classified in 10 classes(0-9).\n",
    "n_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = load_data('data/01.npz', 'data/label.npy', time_steps)\n",
    "X_train2, X_test2, y_train2, y_test2 = load_data('data/02.npz', 'data/label.npy', time_steps)\n",
    "X_train3, X_test3, y_train3, y_test3 = load_data('data/03.npz', 'data/label.npy', time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2, X_train3))\n",
    "X_test = np.concatenate((X_test1, X_test2, X_test3))\n",
    "y_train = np.concatenate((y_train1, y_train2, y_train3))\n",
    "y_test = np.concatenate((y_test1, y_test2, y_test3))\n",
    "# X_train, X_test, y_train, y_test = X_train2, X_test2, y_train2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(copy=False)\n",
    "X_train = X_train.reshape((-1, 310))\n",
    "X_test = X_test.reshape((-1, 310))\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train = X_train.reshape((-1, time_steps, 310))\n",
    "X_test = X_test.reshape((-1, time_steps, 310))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#size of batch\n",
    "batch_size=100\n",
    "epoch = 30\n",
    "max_steps = epoch * X_train.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights and biases of appropriate shape to accomplish above task\n",
    "weights=tf.Variable(tf.random_normal([num_units,n_classes]))\n",
    "bias=tf.Variable(tf.random_normal([n_classes]))\n",
    "#defining placeholders\n",
    "#input image placeholder\n",
    "data_placeholder=tf.placeholder(tf.float32,[None,time_steps,features])\n",
    "#input label placeholder\n",
    "label_placeholder=tf.placeholder(tf.int64,[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=tf.unstack(data_placeholder ,time_steps,1)\n",
    "lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\n",
    "outputs,_=rnn.static_rnn(lstm_layer,input,dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "final_output = tf.nn.dropout(outputs[-1], keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=tf.matmul(final_output,weights)+bias\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "  labels=label_placeholder))\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), label_placeholder)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0, Test accuracy 0.433639\n",
      "Epoch   1, Test accuracy 0.675535\n",
      "Epoch   2, Test accuracy 0.647095\n",
      "Epoch   3, Test accuracy 0.766972\n",
      "Epoch   4, Test accuracy 0.776758\n",
      "Epoch   5, Test accuracy 0.843731\n",
      "Epoch   6, Test accuracy 0.818349\n",
      "Epoch   7, Test accuracy 0.89052\n",
      "Epoch   8, Test accuracy 0.855352\n",
      "Epoch   9, Test accuracy 0.910092\n",
      "Epoch  10, Test accuracy 0.903364\n",
      "Epoch  11, Test accuracy 0.892049\n",
      "Epoch  12, Test accuracy 0.912844\n",
      "Epoch  13, Test accuracy 0.911621\n",
      "Epoch  14, Test accuracy 0.902752\n",
      "Epoch  15, Test accuracy 0.908257\n",
      "Epoch  16, Test accuracy 0.917125\n",
      "Epoch  17, Test accuracy 0.916208\n",
      "Epoch  18, Test accuracy 0.923547\n",
      "Epoch  19, Test accuracy 0.90367\n",
      "Epoch  20, Test accuracy 0.909174\n",
      "Epoch  21, Test accuracy 0.908868\n",
      "Epoch  22, Test accuracy 0.902752\n",
      "Epoch  23, Test accuracy 0.918349\n",
      "Epoch  24, Test accuracy 0.914985\n",
      "Epoch  25, Test accuracy 0.904281\n",
      "Epoch  26, Test accuracy 0.910398\n",
      "Epoch  27, Test accuracy 0.918349\n",
      "Epoch  28, Test accuracy 0.915902\n",
      "Epoch  29, Test accuracy 0.908868\n",
      "Test accuracy 0.916208\n",
      "Total time: 67.59s\n"
     ]
    }
   ],
   "source": [
    "beginTime = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Repeat max_steps times\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        # Generate input data batch\n",
    "        indices = np.random.choice(X_train.shape[0], batch_size)\n",
    "        data_batch = X_train[indices]\n",
    "        label_batch = y_train[indices]\n",
    "\n",
    "        # Periodically print out the model's current accuracy\n",
    "        if i * batch_size // X_train.shape[0] != (i - 1) * batch_size // X_train.shape[0]:\n",
    "#         if i * batch_size // X_train.shape[0] != (i - 1) * batch_size // X_train.shape[0] and (i * batch_size // X_train.shape[0]) % 5 == 0:\n",
    "#             train_accuracy = sess.run(accuracy, feed_dict={\n",
    "#                 data_placeholder: data_batch, label_placeholder: label_batch})\n",
    "#             print('Step {:5d}: training accuracy {:g}'.format(i, train_accuracy))\n",
    "            test_accuracy = sess.run(accuracy, feed_dict={\n",
    "                data_placeholder: X_test,\n",
    "                label_placeholder: y_test,\n",
    "                keep_prob: 1.0})\n",
    "            print('Epoch {:3d}, Test accuracy {:g}'.format(i * batch_size // X_train.shape[0], test_accuracy))\n",
    "\n",
    "        # Perform a single training step\n",
    "        sess.run(train_step, feed_dict={data_placeholder: data_batch,\n",
    "                                        label_placeholder: label_batch,\n",
    "                                        keep_prob: 0.5})\n",
    "\n",
    "    # After finishing the training, evaluate on the test set\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={\n",
    "        data_placeholder: X_test,\n",
    "        label_placeholder: y_test,\n",
    "        keep_prob: 1.0})\n",
    "    print('Test accuracy {:g}'.format(test_accuracy))\n",
    "\n",
    "endTime = time.time()\n",
    "print('Total time: {:5.2f}s'.format(endTime - beginTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
